# SVM - Support Vector Machine
## Lagrange Multipliers
The minimum of a function $f(x, y)$ subject to the constraint $g(x,y) = 0$ happens when $L(x,y, \lambda) = f(x, y) - \lambda g(x,y)$ is maximized.
	â†’ $\nabla L = 0$

SVM maximizes the margin by minimizing $\frac{1}{2}|w|^{2}$ such that $y_{i}(w\cdot x_{i}+b) \ge 1$

Maximizing the margin depends only on the dot product of pairs of support vectors.


## What do inner products mean?
- Inner product provide a measure of similarity
- If two vectors are perpendicular (i.e. completely dissimilar), their inner product is 0.
- If two vectors are parallel, their inner product is 1.

- Case 1: If two features are completely dissimilar, they don't contribute to L.
- Case 2: If two features are similar and predict the same class, they decrease L.
- Case 3: If two features are similar and predict different classes, they increase L.

## Kernel Trick
